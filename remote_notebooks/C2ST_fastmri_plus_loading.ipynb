{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing installs in requirements.txt\n",
    "# h5py, pandas, matplotlib\n",
    "# Numpy conflict: solved by `conda install numpy=1.20`\n",
    "\n",
    "# /home/timsey/anaconda3/envs/c2st/lib/python3.9/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
    "#   return torch._C._cuda_getDeviceCount() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model params (eps, sigma, sigma0_u)\n",
    "#  dataset_size = 5000: 1000 train, 250 val, 1250 test.\n",
    "#   val:     val_loss = -9.1335e-15, mmd2 = 9.1551e-19, varEst = 4.7101e-11, Kxyxy.shape = [250 x 250] (full batch).\n",
    "#    NOTE: varEst lower than 1e-8, which is the margin factor in the sqrt for the loss.\n",
    "#   train: train_loss = -1.4601e-13, Kxyxy.shape = [64 x 64] or [40 x 40] (batched) --> hardly any training.\n",
    "#   val:     val_loss = -1.8280e-14, mmd2 = 1.8323e-18, varEst = 4.7101e-11, Kxyxy.shape = [250 x 250] (full batch).\n",
    "#   test:   test_loss = -2.0786e-14, mmd2 = 2.0797e-18, varEst = 1.0697e-11, Kxyxy.shape = [1250 x 1250] (full batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old model params (eps, sigma, sigma0_u)\n",
    "#  dataset_size = 5000: 1000 train, 250 val, 1250 test.\n",
    "#   val:     val_loss = 0.,  mmd2 = 0., varEst = 8.4219e-5, Kxyxy.shape = [250 x 250] (full batch): same as epoch 1 (below).\n",
    "#   train: train_loss = -7.5692e-18, Kxyxy.shape = [64 x 64] or [40 x 40] (batched) --> hardly any training.\n",
    "#   val:     val_loss = 0.,  mmd2 = 0., varEst = 8.4219e-5, Kxyxy.shape = [250 x 250] (full batch): same as epoch 0 (above).\n",
    "#   test:   test_loss = -0., mmd2 = 0., varEst = 1.9054e-6, Kxyxy.shape = [1250 x 1250] (full batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import xml.etree.ElementTree as etree\n",
    "from pathlib import Path\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    NamedTuple,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "from warnings import warn\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.fft\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"darkgrid\")\n",
    "\n",
    "import json\n",
    "from scipy.stats import combine_pvalues\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "save_dir = Path(\"/home/timsey/Projects/c2st-e/results/mri_figs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base_dir = Path(\"/home/timsey/Projects/c2st-e/results/mri/\")\n",
    "results_name = \"results.json\"\n",
    "\n",
    "results_datetime = \"2022-09-23/18:09:04\"  # Base results: individual experiments, all settings, multiple sizes\n",
    "\n",
    "results_path = results_base_dir / results_datetime / results_name\n",
    "\n",
    "with open(results_path, 'r') as f:\n",
    "    results_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Type-I and Type-II errors for given dataset size.\n",
    "\n",
    "alpha = 0.05  # Threshold\n",
    "errors_per_size = {}\n",
    "for dataset_size, ds_dict in results_dict.items():\n",
    "    e_vals = defaultdict(list)\n",
    "    p_vals = defaultdict(list)\n",
    "    print(f\"\\n{dataset_size} points, {len(ds_dict)} samples.\")\n",
    "    for dataset_ind, di_dict in ds_dict.items():\n",
    "        for setting, set_dict in di_dict.items():\n",
    "            e_vals[setting].append(set_dict[\"e_val\"])\n",
    "            p_vals[setting].append(set_dict[\"p_val\"])\n",
    "#             test_loss = setting[\"test_loss\"]\n",
    "#             test_acc = setting[\"test_acc\"]\n",
    "   \n",
    "    if dataset_size in [\"200\", \"400\", \"1000\"]:\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        type2_evals = np.array(e_vals['2'])\n",
    "        reject_frac = ((1 / type2_evals) < alpha).mean()\n",
    "        print(\"Fraction of E-values > 1:\", (type2_evals > 1).mean())\n",
    "        # Plot the 10-log\n",
    "        logmin = np.log(np.min(type2_evals)) / np.log(10) - 0.5\n",
    "        logmax = np.log(np.max(type2_evals)) / np.log(10) + 0.5\n",
    "        n, bins, patches = plt.hist(\n",
    "            type2_evals.astype(np.float128), bins=np.logspace(logmin, logmax, 101), color=\"royalblue\"\n",
    "        )\n",
    "        plt.axvline(1 / alpha, linestyle=\"--\", label=\"1 / alpha\", color=\"darkorange\")\n",
    "        plt.fill_between(\n",
    "            np.logspace(np.log(1 / alpha) - 1.71, logmax, 10),  # why 1.71 though?\n",
    "            np.zeros(10), \n",
    "            np.max(n) * np.ones(10) + 1, \n",
    "            color=\"red\", \n",
    "            alpha=0.1, \n",
    "            label=\"rejection region\",\n",
    "        )\n",
    "        plt.title(f\"Type-II, {dataset_size} points, 1 - error = rejection frac. = {reject_frac:.2f}\", fontsize=15)\n",
    "        plt.legend()\n",
    "        plt.xscale('log')\n",
    "        plt.xlim(10**logmin, 10**logmax)\n",
    "        plt.ylim(0, np.max(n) + 1)\n",
    "        plt.ylabel(\"count\", fontsize=15)\n",
    "        plt.xlabel(\"E-value\", fontsize=15)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        type2_pvals = np.array(p_vals['2'])\n",
    "        reject_frac = (type2_pvals < alpha).mean()\n",
    "        # Plot the 10-log\n",
    "        logmin = np.log(np.min(type2_pvals) + 1e-8) / np.log(10) - 0.5\n",
    "        logmax = np.log(np.max(type2_pvals)) / np.log(10) + 0.5\n",
    "        n, bins, patches = plt.hist(\n",
    "            type2_pvals.astype(np.float128), bins=np.logspace(logmin, logmax, 100), color=\"royalblue\"\n",
    "        )\n",
    "        plt.axvline(alpha, linestyle=\"--\", label=\"alpha\", color=\"darkorange\")\n",
    "        plt.fill_between(\n",
    "            np.logspace(logmin, np.log(alpha) + 1.71, 10),  # why 1.71 though?\n",
    "            np.zeros(10), \n",
    "            np.max(n) * np.ones(10) + 1, \n",
    "            color=\"red\", \n",
    "            alpha=0.1, \n",
    "            label=\"rejection region\",\n",
    "        )\n",
    "        plt.title(f\"Type-II, {dataset_size} points, 1 - error = rejection frac. = {reject_frac:.2f}\", fontsize=15)\n",
    "        plt.legend()\n",
    "        plt.xscale('log')\n",
    "        plt.xlim(10**logmin, 10**logmax)\n",
    "        plt.ylim(0, np.max(n) + 1)\n",
    "        plt.xlabel(\"p-value\", fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    errors_per_setting = {}\n",
    "    for setting in e_vals.keys():\n",
    "        # 0 if accept, 1 if reject\n",
    "        e_decisions = (1 / np.array(e_vals[setting])) < alpha\n",
    "        p_decisions = np.array(p_vals[setting]) < alpha\n",
    "        if setting in [\"1a\", \"1b\"]:  # Type-I error\n",
    "            # Rejection of null is incorrect\n",
    "            e_error = e_decisions.sum() / len(e_decisions)\n",
    "            p_error = p_decisions.sum() / len(p_decisions)\n",
    "        elif setting == \"2\":  # Type-II error\n",
    "            # Rejection of null is correct\n",
    "            e_error = 1 - e_decisions.sum() / len(e_decisions)\n",
    "            p_error = 1 - p_decisions.sum() / len(p_decisions)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown setting.\")\n",
    "            \n",
    "        errors_per_setting[setting] = {\"e_error\": e_error, \"p_error\": p_error}\n",
    "    pprint(errors_per_setting)\n",
    "    \n",
    "    errors_per_size[dataset_size] = errors_per_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots per error\n",
    "dataset_sizes = np.array([int(key) for key in errors_per_size.keys()])\n",
    "plot_sizes = dataset_sizes / 1000\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "width = 0.08\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Type-1a error\", fontsize=18)\n",
    "e_error1a = [val[\"1a\"][\"e_error\"] for val in errors_per_size.values()]\n",
    "p_error1a = [val[\"1a\"][\"p_error\"] for val in errors_per_size.values()]\n",
    "plt.bar(plot_sizes-width/2, e_error1a, width=width, label=\"E-value\", color=\"darkorange\")\n",
    "plt.bar(plot_sizes+width/2, p_error1a, width=width, label=\"p-value\", color=\"royalblue\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"error value\", fontsize=15)\n",
    "plt.xlabel(\"dataset size (x1000)\", fontsize=15)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Type-1b error\", fontsize=18)\n",
    "e_error1b = [val[\"1b\"][\"e_error\"] for val in errors_per_size.values()]\n",
    "p_error1b = [val[\"1b\"][\"p_error\"] for val in errors_per_size.values()]\n",
    "plt.bar(plot_sizes-width/2, e_error1b, width=width, label=\"E-value\", color=\"darkorange\")\n",
    "plt.bar(plot_sizes+width/2, p_error1b, width=width, label=\"p-value\", color=\"royalblue\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"error value\", fontsize=15)\n",
    "plt.xlabel(\"dataset size (x1000)\", fontsize=15)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Type-2 error\", fontsize=18)\n",
    "e_error2 = [val[\"2\"][\"e_error\"] for val in errors_per_size.values()]\n",
    "p_error2 = [val[\"2\"][\"p_error\"] for val in errors_per_size.values()]\n",
    "plt.bar(plot_sizes-width/2, e_error2, width=width, label=\"E-value\", color=\"darkorange\")\n",
    "plt.bar(plot_sizes+width/2, p_error2, width=width, label=\"p-value\", color=\"royalblue\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"error value\", fontsize=15)\n",
    "plt.xlabel(\"dataset size (x1000)\", fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots: what do we actually want to plot here? Only have single error per setting, so we want to \n",
    "# plot individual E-/p-values?\n",
    "# They vary a lot across the 100 samples though (see some of the histograms two cells up); we would use log space.\n",
    "# Histograms might be more informative than violin plot.\n",
    "\n",
    "# plt.figure(figsize=(15, 4))\n",
    "\n",
    "# p_error1a = [val[\"1a\"][\"p_error\"] for val in errors_per_size.values()]\n",
    "\n",
    "# sizes = list(sorted(errors_per_size.keys(), key=lambda x: int(x)))\n",
    "# max_cols = 4\n",
    "# cols = min(max_cols, len(sizes))\n",
    "# rows = len(sizes) // cols + 1 if len(sizes) % cols != 0 else len(sizes) // cols\n",
    "\n",
    "# xs = [\"E-1a\", \"p-1a\", \"E-1b\", \"p-1b\", \"E-2\", \"p-2\"]\n",
    "# for i, size in enumerate(sizes):\n",
    "#     plt.subplot(rows, cols, i+1)\n",
    "#     e_error1a = errors_per_size[size][\"1a\"][\"e_error\"]\n",
    "#     p_error1a = errors_per_size[size][\"1a\"][\"p_error\"]\n",
    "#     e_error1b = errors_per_size[size][\"1b\"][\"e_error\"]\n",
    "#     p_error1b = errors_per_size[size][\"1b\"][\"p_error\"]\n",
    "#     e_error2 = errors_per_size[size][\"2\"][\"e_error\"]\n",
    "#     p_error2 = errors_per_size[size][\"2\"][\"p_error\"]\n",
    "    \n",
    "#     vp = plt.violinplot(\n",
    "#         [e_error1a, p_error1a, e_error1b, p_error1b, e_error2, p_error2], \n",
    "#         widths=0.6, \n",
    "#         showmeans=True, \n",
    "#         showextrema=True,\n",
    "#     )\n",
    "\n",
    "#     plt.title(f\"Dataset size: {size}\", fontsize=15)\n",
    "#     plt.xticks(xs, bar_labels)\n",
    "#     plt.ylabel(\"error value\", fontsize=15)\n",
    "#     for i, pc in enumerate(vp[\"bodies\"]):\n",
    "#         if i == 0:\n",
    "#             pc.set_facecolor(\"darkorange\")\n",
    "#         else:\n",
    "#             pc.set_facecolor(\"royalblue\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Pareto front\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "ex, ey1, ey2, px, py1, py2 = [], [], [], [], [], []\n",
    "for size, vals in errors_per_size.items():\n",
    "    e1a = 1.0 - vals[\"1a\"][\"e_error\"]\n",
    "    e1b = 1.0 - vals[\"1b\"][\"e_error\"]\n",
    "    e2 = 1.0 - vals[\"2\"][\"e_error\"]\n",
    "    ex.append(e2)\n",
    "    ey1.append(e1a)\n",
    "    ey2.append(e1b)\n",
    "    \n",
    "    p1a = 1.0 - vals[\"1a\"][\"p_error\"]\n",
    "    p1b = 1.0 - vals[\"1b\"][\"p_error\"]\n",
    "    p2 = 1.0 - vals[\"2\"][\"p_error\"]\n",
    "    px.append(p2)\n",
    "    py1.append(p1a)\n",
    "    py2.append(p1b)\n",
    "    \n",
    "    plt.annotate(f\"{size}\", (e2, e1a), fontsize=12)\n",
    "    plt.annotate(f\"{size}\", (e2, e1b), fontsize=12)\n",
    "    plt.annotate(f\"{size}\", (p2, p1a), fontsize=12)\n",
    "    plt.annotate(f\"{size}\", (p2, p1b), fontsize=12)\n",
    "\n",
    "plt.scatter(ex, ey1, label=\"E-value\", c=\"darkorange\")\n",
    "plt.scatter(ex, ey2, label=\"E-value\", c=\"darkorange\")\n",
    "\n",
    "plt.scatter(px, py1, label=\"p-value\", c=\"royalblue\")\n",
    "plt.scatter(px, py2, label=\"p-value\", c=\"royalblue\")\n",
    "\n",
    "plt.xlabel(\"1 - type-II error\", fontsize=15)\n",
    "plt.ylabel(\"1 - type-I error\", fontsize=15)\n",
    "# Make sure labels are not duplicated\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "if save_figs:\n",
    "    plot_save_dir = save_dir\n",
    "    plot_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_name = f\"mri_pareto_front\"\n",
    "    plt.savefig(plot_save_dir / (save_name + \".pdf\"), dpi=300)\n",
    "    plt.savefig(plot_save_dir / (save_name + \".svg\"), dpi=300)\n",
    "    plt.savefig(plot_save_dir / (save_name + \".png\"), dpi=300)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-analysis experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 100 samples, sizes (200, 400, 1K), Type-II\n",
    "# meta_analysis_folder = Path(\"/home/timsey/Projects/c2st-e/results/mri/meta_analysis_sept26/\")\n",
    "# # 100 samples, sizes (200, 400, 1K), Type-Ia&1b\n",
    "# meta_analysis_folder = Path(\"/home/timsey/Projects/c2st-e/results/mri/meta_analysis_sept27\")\n",
    "\n",
    "# all_results_dicts = []\n",
    "# for date_folder in meta_analysis_folder.iterdir():\n",
    "#     for time_folder in date_folder.iterdir():\n",
    "#         results_file = time_folder / \"results.json\"\n",
    "#         if not results_file.exists():\n",
    "#             print(f\"Missing results folder in: {time_folder}\")\n",
    "#             continue\n",
    "\n",
    "#         with open(results_file, 'r') as f:\n",
    "#             results_dict = json.load(f)\n",
    "#         all_results_dicts.append(results_dict)\n",
    "\n",
    "# print(len(all_results_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 samples, sizes (200, 400, 1K), Type-II\n",
    "meta_analysis_folder2 = Path(\"/home/timsey/Projects/c2st-e/results/mri/meta_analysis_sept26/\")\n",
    "# 100 samples, sizes (200, 400, 1K), Type-Ia&1b\n",
    "meta_analysis_folder1 = Path(\"/home/timsey/Projects/c2st-e/results/mri/meta_analysis_sept27\")\n",
    "\n",
    "meta_analysis_folders = [meta_analysis_folder1, meta_analysis_folder2]\n",
    "\n",
    "all_results_dicts = []\n",
    "for meta_analysis_folder in meta_analysis_folders:\n",
    "    for date_folder in meta_analysis_folder.iterdir():\n",
    "        for time_folder in date_folder.iterdir():\n",
    "            results_file = time_folder / \"results.json\"\n",
    "            if not results_file.exists():\n",
    "                print(f\"Missing results folder in: {time_folder}\")\n",
    "                continue\n",
    "\n",
    "            with open(results_file, 'r') as f:\n",
    "                results_dict = json.load(f)\n",
    "            all_results_dicts.append(results_dict)\n",
    "\n",
    "print(len(all_results_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Type-I and Type-II errors per experiment (over n partitions), and\n",
    "# also compute E-value of the combined partitions (meta-analysis).\n",
    "\n",
    "alpha = 0.05  # Threshold\n",
    "\n",
    "meta_analysis_dict = defaultdict(dict)\n",
    "for i, results_dict in enumerate(all_results_dicts):\n",
    "#     print(f\"Experiment {i+1}/{len(all_results_dicts)}\")\n",
    "    for dataset_size, ds_dict in results_dict.items():\n",
    "        e_vals = defaultdict(list)\n",
    "        p_vals = defaultdict(list)\n",
    "#         print(f\"{dataset_size} points, {len(ds_dict)} partitions.\")\n",
    "        for partition_ind, partition_dict in ds_dict.items():\n",
    "            # Each ind is now a partition\n",
    "            for setting, set_dict in partition_dict.items():\n",
    "                e_vals[setting].append(set_dict[\"e_val\"])\n",
    "                p_vals[setting].append(set_dict[\"p_val\"])\n",
    "    #             test_loss = setting[\"test_loss\"]\n",
    "    #             test_acc = setting[\"test_acc\"]\n",
    "\n",
    "        errors_per_setting = {}\n",
    "        for setting in e_vals.keys():\n",
    "            # 0 if accept, 1 if reject\n",
    "            e_decisions = (1 / np.array(e_vals[setting])) < alpha\n",
    "            p_decisions = np.array(p_vals[setting]) < alpha\n",
    "            if setting in [\"1a\", \"1b\"]:  # Type-I error\n",
    "                # Rejection of null is incorrect\n",
    "                e_error = e_decisions.sum() / len(e_decisions)\n",
    "                p_error = p_decisions.sum() / len(p_decisions)\n",
    "            elif setting == \"2\":  # Type-II error\n",
    "                # Rejection of null is correct\n",
    "                e_error = 1 - e_decisions.sum() / len(e_decisions)\n",
    "                p_error = 1 - p_decisions.sum() / len(p_decisions)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown setting.\")\n",
    "\n",
    "#             print(\"Individual E-values:\", e_vals[setting])\n",
    "            fisher_stat, comb_p_value = combine_pvalues(p_vals[setting])\n",
    "            errors_per_setting[setting] = {\n",
    "                \"e_error_indiv\": e_error,  # E-value error computed over partitions (by treating them as different experiments)\n",
    "                \"p_error_indiv\": p_error,  # Same, but for p-value\n",
    "                \"e_value_prod\": np.prod(e_vals[setting]),  # Combine E-values: multiplication over all partitions (experiments)\n",
    "                \"e_value_avg\": np.mean(e_vals[setting]),\n",
    "                \"p_value_comb\": comb_p_value,  # Combine p-values over partitions using Fisher combination\n",
    "            }\n",
    "    \n",
    "#         pprint(errors_per_setting)\n",
    "        meta_analysis_dict[dataset_size][i] = errors_per_setting\n",
    "#         print(meta_analysis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the product E-values as new E-value, and compute error over M samples of the whole N-partition experiment.\n",
    "\n",
    "e_prod_errors_per_size = defaultdict(dict)\n",
    "\n",
    "for dataset_size, sample_dict in meta_analysis_dict.items():\n",
    "    indiv_e_errors = defaultdict(list)\n",
    "    indiv_p_errors = defaultdict(list)\n",
    "    prod_e_values = defaultdict(list)\n",
    "    avg_e_values = defaultdict(list)\n",
    "    comb_p_values = defaultdict(list)\n",
    "    for sample_ind, settings_dict in sample_dict.items():\n",
    "        for setting, error_dict in settings_dict.items():\n",
    "            e_error_indiv = error_dict[\"e_error_indiv\"]\n",
    "            p_error_indiv = error_dict[\"p_error_indiv\"]\n",
    "            e_value_prod = error_dict[\"e_value_prod\"]\n",
    "            e_value_avg = error_dict[\"e_value_avg\"]\n",
    "            p_value_comb = error_dict[\"p_value_comb\"]\n",
    "            indiv_e_errors[setting].append(e_error_indiv)\n",
    "            indiv_p_errors[setting].append(p_error_indiv)\n",
    "            prod_e_values[setting].append(e_value_prod)\n",
    "            avg_e_values[setting].append(e_value_avg)\n",
    "            comb_p_values[setting].append(p_value_comb)\n",
    "    \n",
    "    for setting, prod_es in prod_e_values.items():\n",
    "        comb_p = comb_p_values[setting]\n",
    "        # 0 if accept, 1 if reject\n",
    "        e_decisions = (1 / np.array(prod_es)) < alpha\n",
    "        e_decisions_by_avg = (1 / np.array(avg_e_values[setting])) < alpha\n",
    "        p_decisions = np.array(comb_p) < alpha\n",
    "        if setting in [\"1a\", \"1b\"]:  # Type-I error\n",
    "            # Rejection of null is incorrect\n",
    "            e_error = e_decisions.sum() / len(e_decisions)\n",
    "            e_error_by_avg = e_decisions_by_avg.sum() / len(e_decisions_by_avg)\n",
    "            p_error = p_decisions.sum() / len(p_decisions)\n",
    "        elif setting == \"2\":  # Type-II error\n",
    "            # Rejection of null is correct\n",
    "            e_error = 1 - e_decisions.sum() / len(e_decisions)\n",
    "            e_error_by_avg = 1 - e_decisions_by_avg.sum() / len(e_decisions_by_avg)\n",
    "            p_error = 1 - p_decisions.sum() / len(p_decisions)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown setting.\")\n",
    "\n",
    "        e_prod_errors_per_size[dataset_size][setting] = {\n",
    "            \"prod_e_error\": e_error,\n",
    "            \"avg_e_error\": e_error_by_avg,  # Error using average of experiment E-value instead of product\n",
    "            \"comb_p_error\": p_error,\n",
    "            \"indiv_e_error_hist\": indiv_e_errors[setting],\n",
    "            \"indiv_p_error_hist\": indiv_p_errors[setting],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = list(e_prod_errors_per_size.values())\n",
    "num_sizes = len(dataset_sizes)\n",
    "\n",
    "settings = list(list(e_prod_errors_per_size.values())[0].keys())\n",
    "num_settings = len(settings)\n",
    "\n",
    "plt.figure(figsize=(6*num_sizes, 4*num_settings))\n",
    "plt.suptitle(\"Histograms of errors.\", fontsize=18)\n",
    "for i, (dataset_size, size_results) in enumerate(e_prod_errors_per_size.items()):\n",
    "    for j, (setting, setting_results) in enumerate(size_results.items()):\n",
    "        plt.subplot(num_settings, num_sizes, num_sizes*j+i+1)\n",
    "        plt.hist(setting_results[\"indiv_e_error_hist\"], bins=np.arange(0, 1.01, 1/11), label=\"E-value\", color=\"darkorange\", alpha=0.5)\n",
    "        plt.hist(setting_results[\"indiv_p_error_hist\"], bins=np.arange(0, 1.01, 1/11), label=\"p-value\", color=\"royalblue\", alpha=0.5)\n",
    "    \n",
    "        plt.title(f\"Type-{setting} errors ({dataset_size} points).\", fontsize=15)\n",
    "        plt.xlabel(\"error value\", fontsize=15)\n",
    "        if i == 0:\n",
    "            plt.ylabel(\"error count\", fontsize=15)\n",
    "        plt.legend()\n",
    "    \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = list(list(e_prod_errors_per_size.values())[0].keys())\n",
    "# num_settings = len(settings)\n",
    "\n",
    "# plt.figure(figsize=(12, 4*num_settings))\n",
    "# plt.suptitle(f\"Meta-analysis: {int(partition_ind) + 1} partitions ({len(all_results_dicts)} samples).\", fontsize=18)\n",
    "# for i, setting in enumerate(settings):\n",
    "#     bar_labels = []\n",
    "#     e_error_vals = []\n",
    "#     p_error_vals = []\n",
    "#     e_error_vals_indiv_avg = []\n",
    "#     p_error_vals_indiv_avg = []\n",
    "#     for dataset_size, results in e_prod_errors_per_size.items():\n",
    "#         bar_labels.append(dataset_size)\n",
    "#         e_error_vals.append(results[setting][\"prod_e_error\"])\n",
    "#         p_error_vals.append(results[setting][\"comb_p_error\"])\n",
    "#         e_error_vals_indiv_avg.append(np.mean(results[setting][\"indiv_e_error_hist\"]))\n",
    "#         p_error_vals_indiv_avg.append(np.mean(results[setting][\"indiv_p_error_hist\"]))\n",
    "    \n",
    "#     width=0.2\n",
    "#     xs = np.array(list(range(len(e_error_vals))))\n",
    "    \n",
    "#     plt.subplot(num_settings, 2, 2*i+1)\n",
    "#     plt.bar(xs-width/2, e_error_vals, width=width, label=\"E-value (comb)\", color=\"navajowhite\")\n",
    "#     plt.bar(xs+width/2, e_error_vals_indiv_avg, width=width, label=\"E-value (indiv)\", color=\"darkorange\")\n",
    "#     plt.title(f\"E-value type-{setting} errors\", fontsize=15)\n",
    "#     plt.xlabel(\"dataset size\", fontsize=15)\n",
    "#     plt.xticks(xs, bar_labels)\n",
    "#     plt.ylabel(\"error value\", fontsize=15)\n",
    "#     plt.ylim(0, .1)\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(num_settings, 2, 2*i+2)\n",
    "#     plt.bar(xs-width/2, p_error_vals, width=width, label=\"p-value (comb)\", color=\"deepskyblue\")\n",
    "#     plt.bar(xs+width/2, p_error_vals_indiv_avg, width=width, label=\"p-value (indiv)\", color=\"royalblue\")\n",
    "#     plt.title(f\"p-value type-{setting} errors\", fontsize=15)\n",
    "#     plt.xlabel(\"dataset size\", fontsize=15)\n",
    "#     plt.xticks(xs, bar_labels)\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.legend()\n",
    "    \n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = list(list(e_prod_errors_per_size.values())[0].keys())\n",
    "num_settings = len(settings)\n",
    "\n",
    "plt.figure(figsize=(12, 4*num_settings))\n",
    "plt.suptitle(f\"Meta-analysis: {int(partition_ind) + 1} partitions ({len(all_results_dicts)} samples).\", fontsize=18)\n",
    "for i, setting in enumerate(settings):\n",
    "    bar_labels = []\n",
    "    e_error_vals = []\n",
    "    e_by_avg_error_vals = []\n",
    "    p_error_vals = []\n",
    "    e_error_vals_indiv_avg = []\n",
    "    p_error_vals_indiv_avg = []\n",
    "    for dataset_size, results in e_prod_errors_per_size.items():\n",
    "        bar_labels.append(dataset_size)\n",
    "        e_error_vals.append(results[setting][\"prod_e_error\"])\n",
    "        e_by_avg_error_vals.append(results[setting][\"avg_e_error\"])\n",
    "        p_error_vals.append(results[setting][\"comb_p_error\"])\n",
    "        e_error_vals_indiv_avg.append(np.mean(results[setting][\"indiv_e_error_hist\"]))\n",
    "        p_error_vals_indiv_avg.append(np.mean(results[setting][\"indiv_p_error_hist\"]))\n",
    "    \n",
    "    width=0.2\n",
    "    xs = np.array(list(range(len(e_error_vals))))\n",
    "    \n",
    "    plt.subplot(num_settings, 2, 2*i+1)\n",
    "    plt.bar(xs-width, e_by_avg_error_vals, width=width, label=\"E-value (avg)\", color=\"goldenrod\")\n",
    "    plt.bar(xs, e_error_vals, width=width, label=\"E-value (comb)\", color=\"navajowhite\")\n",
    "    plt.bar(xs+width, e_error_vals_indiv_avg, width=width, label=\"E-value (indiv)\", color=\"darkorange\")\n",
    "    plt.title(f\"E-value type-{setting} errors\", fontsize=15)\n",
    "    plt.xlabel(\"dataset size\", fontsize=15)\n",
    "    plt.xticks(xs, bar_labels)\n",
    "    plt.ylabel(\"error value\", fontsize=15)\n",
    "    if setting == \"2\":\n",
    "        plt.ylim(0, 1)\n",
    "    else:\n",
    "        plt.ylim(0, 0.1)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(num_settings, 2, 2*i+2)\n",
    "    plt.bar(xs-width/2, p_error_vals, width=width, label=\"p-value (comb)\", color=\"deepskyblue\")\n",
    "    plt.bar(xs+width/2, p_error_vals_indiv_avg, width=width, label=\"p-value (indiv)\", color=\"royalblue\")\n",
    "    plt.title(f\"p-value type-{setting} errors\", fontsize=15)\n",
    "    plt.xlabel(\"dataset size\", fontsize=15)\n",
    "    plt.xticks(xs, bar_labels)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "\n",
    "if save_figs:\n",
    "    plot_save_dir = save_dir\n",
    "    plot_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_name = f\"mri_meta_{'_'.join(settings)}_withavg\"\n",
    "    plt.savefig(plot_save_dir / (save_name + \".pdf\"), dpi=300)\n",
    "    plt.savefig(plot_save_dir / (save_name + \".svg\"), dpi=300)\n",
    "    plt.savefig(plot_save_dir / (save_name + \".png\"), dpi=300)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsync -a timsey@146.50.28.109:~/Projects/c2st-e/results/mri_figs/ ~/Projects/c2st-e/results/mri_figs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code that is now in PyCharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastMRI, NeurIPS2020 splits\n",
    "fastmri_data_folder = Path(\"/home/timsey/HDD/data/fastMRI/singlecoil\")\n",
    "train = fastmri_data_folder / \"singlecoil_train\"\n",
    "val = fastmri_data_folder / \"singlecoil_val\"\n",
    "test = fastmri_data_folder / \"singlecoil_test\"\n",
    "\n",
    "# fastMRI+\n",
    "plus_data_folder = Path(\"/home/timsey/Projects/fastmri-plus/Annotations/\")\n",
    "pathology_path = plus_data_folder / \"knee.csv\"\n",
    "checked_path = plus_data_folder / \"knee_file_list.csv\"\n",
    "\n",
    "# Skip final row because it's \"Knee data\" for some reason\n",
    "pathology_df = pd.read_csv(pathology_path, index_col=None, header=0)\n",
    "check_df = pd.read_csv(checked_path, names=[\"file\"], index_col=None, header=None, skipfooter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe for which volume is clean and which isn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathology_info(folders_to_check, pathology_df, check_df):\n",
    "    not_checked = defaultdict(bool)\n",
    "    no_pathologies = defaultdict(bool)\n",
    "    any_pathologies = defaultdict(bool)\n",
    "    \n",
    "    all_pathologies = set([])\n",
    "\n",
    "    for folder in folders_to_check:\n",
    "        for fname in folder.iterdir():\n",
    "            name = fname.name[:-3]\n",
    "            if name in not_checked or name in no_pathologies or name in any_pathologies:\n",
    "                raise RunTimeError(\"Found volume in multiple partitions!\")\n",
    "\n",
    "            if name not in check_df[\"file\"].values:\n",
    "                not_checked[name] = 1\n",
    "                continue\n",
    "            \n",
    "            pathologies = pathology_df[pathology_df[\"file\"] == name]\n",
    "            all_pathologies = all_pathologies | set(pathologies[\"label\"].values)\n",
    "            num_pathologies = len(pathologies)\n",
    "            if num_pathologies == 0:\n",
    "                no_pathologies[name] = True\n",
    "            else:\n",
    "                any_pathologies[name] = False\n",
    "    return not_checked, no_pathologies, any_pathologies, list(all_pathologies)\n",
    "\n",
    "folders_to_check = [train, val, test]\n",
    "not_checked, no_pathologies, any_pathologies, all_pathologies = get_pathology_info(\n",
    "    folders_to_check, pathology_df, check_df\n",
    ")\n",
    "print(len(not_checked), len(no_pathologies), len(any_pathologies))\n",
    "print(len(all_pathologies), all_pathologies)\n",
    "\n",
    "if len(not_checked) == 0:\n",
    "    clean_volumes = {**no_pathologies, **any_pathologies}\n",
    "else:\n",
    "    clean_volumes = None\n",
    "    raise NotImplementedError(\"Haven't thought of what to do if there are unchecked volumes yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_query(\n",
    "    root: etree.Element,\n",
    "    qlist,\n",
    "    namespace: str = \"http://www.ismrm.org/ISMRMRD\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    ElementTree query function.\n",
    "    This can be used to query an xml document via ElementTree. It uses qlist\n",
    "    for nested queries.\n",
    "    Args:\n",
    "        root: Root of the xml to search through.\n",
    "        qlist: A list of strings for nested searches, e.g. [\"Encoding\",\n",
    "            \"matrixSize\"]\n",
    "        namespace: Optional; xml namespace to prepend query.\n",
    "    Returns:\n",
    "        The retrieved data as a string.\n",
    "    \"\"\"\n",
    "    s = \".\"\n",
    "    prefix = \"ismrmrd_namespace\"\n",
    "\n",
    "    ns = {prefix: namespace}\n",
    "\n",
    "    for el in qlist:\n",
    "        s = s + f\"//{prefix}:{el}\"\n",
    "\n",
    "    value = root.find(s, ns)\n",
    "    if value is None:\n",
    "        raise RuntimeError(\"Element not found\")\n",
    "\n",
    "    return str(value.text)\n",
    "\n",
    "\n",
    "class FastMRIRawDataSample(NamedTuple):\n",
    "    fname: Path\n",
    "    slice_ind: int\n",
    "    metadata: Dict[str, Any]\n",
    "    slice_pathologies: Sequence[str]\n",
    "        \n",
    "        \n",
    "class PathologiesSliceDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that provides access to MR image slices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[str, Path, os.PathLike],\n",
    "        challenge: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        use_dataset_cache: bool = False,\n",
    "        sample_rate: Optional[float] = None,\n",
    "        volume_sample_rate: Optional[float] = None,\n",
    "        dataset_cache_file: Union[str, Path, os.PathLike] = \"dataset_cache.pkl\",\n",
    "        num_cols: Optional[Tuple[int]] = None,\n",
    "        raw_sample_filter: Optional[Callable] = None,\n",
    "        pathology_df: Optional[pd.DataFrame] = None,\n",
    "        clean_volumes: Optional[dict] = None,\n",
    "        use_center_slices_only: Optional[bool] = None,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root: Path to the dataset.\n",
    "            challenge: \"singlecoil\" or \"multicoil\" depending on which challenge\n",
    "                to use.\n",
    "            transform: Optional; A callable object that pre-processes the raw\n",
    "                data into appropriate form. The transform function should take\n",
    "                'kspace', 'target', 'attributes', 'filename', and 'slice' as\n",
    "                inputs. 'target' may be null for test data.\n",
    "            use_dataset_cache: Whether to cache dataset metadata. This is very\n",
    "                useful for large datasets like the brain data.\n",
    "            sample_rate: Optional; A float between 0 and 1. This controls what fraction\n",
    "                of the slices should be loaded. Defaults to 1 if no value is given.\n",
    "                When creating a sampled dataset either set sample_rate (sample by slices)\n",
    "                or volume_sample_rate (sample by volumes) but not both.\n",
    "            volume_sample_rate: Optional; A float between 0 and 1. This controls what fraction\n",
    "                of the volumes should be loaded. Defaults to 1 if no value is given.\n",
    "                When creating a sampled dataset either set sample_rate (sample by slices)\n",
    "                or volume_sample_rate (sample by volumes) but not both.\n",
    "            dataset_cache_file: Optional; A file in which to cache dataset\n",
    "                information for faster load times.\n",
    "            num_cols: Optional; If provided, only slices with the desired\n",
    "                number of columns will be considered.\n",
    "        Added args:\n",
    "            raw_sample_filter: Optional; A callable object that takes an raw_sample\n",
    "                metadata as input and returns a boolean indicating whether the\n",
    "                raw_sample should be included in the dataset.\n",
    "            pathology_df: fastMRI+ pathologies dataframe.\n",
    "            clean_volumes: {filename: volume clean True/False} dictionary.\n",
    "            seed: random seed for shuffling operations (also affect sample_rate operations).\n",
    "            use_center_slices_only: bool, whether to use only the center half of volumes.\n",
    "        \"\"\"\n",
    "        if challenge not in (\"singlecoil\", \"multicoil\"):\n",
    "            raise ValueError('challenge should be either \"singlecoil\" or \"multicoil\"')\n",
    "\n",
    "        if sample_rate is not None and volume_sample_rate is not None:\n",
    "            raise ValueError(\n",
    "                \"either set sample_rate (sample by slices) or volume_sample_rate (sample by volumes) but not both\"\n",
    "            )\n",
    "\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        self.dataset_cache_file = Path(dataset_cache_file)\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Pathologies were labeled using RSS, so always use RSS.\n",
    "#         self.recons_key = (\n",
    "#             \"reconstruction_esc\" if challenge == \"singlecoil\" else \"reconstruction_rss\"\n",
    "#         )\n",
    "        self.recons_key = \"reconstruction_rss\"\n",
    "        \n",
    "        self.raw_samples = []\n",
    "        if raw_sample_filter is None:\n",
    "            self.raw_sample_filter = lambda raw_sample: True\n",
    "        else:\n",
    "            self.raw_sample_filter = raw_sample_filter\n",
    "            \n",
    "        self.pathology_df = pathology_df\n",
    "\n",
    "        # set default sampling mode if none given\n",
    "        if sample_rate is None:\n",
    "            sample_rate = 1.0\n",
    "        if volume_sample_rate is None:\n",
    "            volume_sample_rate = 1.0\n",
    "\n",
    "        # load dataset cache if we have and user wants to use it\n",
    "        if self.dataset_cache_file.exists() and use_dataset_cache:\n",
    "            with open(self.dataset_cache_file, \"rb\") as f:\n",
    "                dataset_cache = pickle.load(f)\n",
    "        else:\n",
    "            dataset_cache = {}\n",
    "\n",
    "        # check if our dataset is in the cache\n",
    "        # if there, use that metadata, if not, then regenerate the metadata\n",
    "        total_slices = 0\n",
    "        total_slices_halved = 0\n",
    "        total_slices_halved_filtered = 0\n",
    "        if dataset_cache.get(root) is None or not use_dataset_cache:\n",
    "            files = list(Path(root).iterdir())\n",
    "            for fname in sorted(files):\n",
    "                metadata, num_slices = self._retrieve_metadata(fname)\n",
    "                total_slices += num_slices\n",
    "        \n",
    "                new_raw_samples = []\n",
    "                for slice_ind in range(num_slices):\n",
    "                    if use_center_slices_only:\n",
    "                        # Use only center half of slices, because edges contains more noise.\n",
    "                        if slice_ind < num_slices // 4 or slice_ind > num_slices * 3 // 4:\n",
    "                            continue\n",
    "                    total_slices_halved += 1\n",
    "                    raw_sample = FastMRIRawDataSample(fname, slice_ind, metadata, [])\n",
    "                    # Apply pathology filter here\n",
    "                    filtered_sample, keep = self.raw_sample_filter(raw_sample)\n",
    "                    if keep:\n",
    "                        new_raw_samples.append(filtered_sample)\n",
    "                        total_slices_halved_filtered += 1\n",
    "                self.raw_samples += new_raw_samples\n",
    "                del metadata[\"pathologies\"]  # Delete df from sample for later collation.\n",
    "\n",
    "            if dataset_cache.get(root) is None and use_dataset_cache:\n",
    "                dataset_cache[root] = self.raw_samples\n",
    "                logging.info(f\"Saving dataset cache to {self.dataset_cache_file}.\")\n",
    "                with open(self.dataset_cache_file, \"wb\") as cache_f:\n",
    "                    pickle.dump(dataset_cache, cache_f)\n",
    "        else:\n",
    "            logging.info(f\"Using dataset cache from {self.dataset_cache_file}.\")\n",
    "            self.raw_samples = dataset_cache[root]\n",
    "\n",
    "        # subsample if desired\n",
    "        if sample_rate < 1.0:  # sample by slice\n",
    "            random.shuffle(self.raw_samples)\n",
    "            num_raw_samples = round(len(self.raw_samples) * sample_rate)\n",
    "            self.raw_samples = self.raw_samples[:num_raw_samples]\n",
    "        elif volume_sample_rate < 1.0:  # sample by volume\n",
    "            vol_names = sorted(list(set([f[0].stem for f in self.raw_samples])))\n",
    "            random.shuffle(vol_names)\n",
    "            num_volumes = round(len(vol_names) * volume_sample_rate)\n",
    "            sampled_vols = vol_names[:num_volumes]\n",
    "            self.raw_samples = [\n",
    "                raw_sample\n",
    "                for raw_sample in self.raw_samples\n",
    "                if raw_sample[0].stem in sampled_vols\n",
    "            ]\n",
    "\n",
    "        if num_cols:\n",
    "            self.raw_samples = [\n",
    "                ex\n",
    "                for ex in self.raw_samples\n",
    "                if ex[2][\"encoding_size\"][1] in num_cols  # type: ignore\n",
    "            ]\n",
    "            \n",
    "        # Equalise number of pathology examples.\n",
    "        # 1) Get min. of num clean / pathology slices for this data partition.\n",
    "        # 2) Randomly throw out extra slices.\n",
    "        print(\"Total\", total_slices)\n",
    "        print(\"Total halved\", total_slices_halved)\n",
    "        print(\"Total halved filtered\", total_slices_halved_filtered)\n",
    "        print(\"Remaining (should match above)\", len(self.raw_samples))\n",
    "        clean_counts = {True: 0, False: 0}\n",
    "        for sample in self.raw_samples:\n",
    "            fname = sample.fname\n",
    "            name = fname.name[:-3]\n",
    "            clean_true_false = clean_volumes[name]\n",
    "            clean_counts[clean_true_false] += 1\n",
    "        print(\"Clean vs. pathology counts\", clean_counts)\n",
    "        max_slices_class = max(clean_counts.keys(), key=(lambda k: clean_counts[k]))\n",
    "        min_slices_class = min(clean_counts.keys(), key=(lambda k: clean_counts[k]))\n",
    "        max_slices = clean_counts[max_slices_class]\n",
    "        # min. of (num clean, num pathology)\n",
    "        min_slices = clean_counts[min_slices_class]\n",
    "#         print(min_slices_class, min_slices)\n",
    "\n",
    "        # Shuffle to randomize what we throw out.\n",
    "        random.shuffle(self.raw_samples)\n",
    "        # Go from the back so we don't mess up the loop when deleting stuff.\n",
    "        for i in reversed(range(len(self.raw_samples))):\n",
    "            if max_slices == min_slices:\n",
    "                break  # Stop once equal number of slices in both classes.\n",
    "            sample = self.raw_samples[i]\n",
    "            fname = sample.fname\n",
    "            name = fname.name[:-3]\n",
    "            # Throw out if class of volume is not min_slices_class, until min_slices remain in each class.\n",
    "            if clean_volumes[name] != min_slices_class:\n",
    "                self.raw_samples.pop(i)\n",
    "                max_slices -= 1\n",
    "        print(\"Final remaining\", len(self.raw_samples))\n",
    "\n",
    "    def _retrieve_metadata(self, fname):\n",
    "        with h5py.File(fname, \"r\") as hf:\n",
    "            et_root = etree.fromstring(hf[\"ismrmrd_header\"][()])\n",
    "\n",
    "            enc = [\"encoding\", \"encodedSpace\", \"matrixSize\"]\n",
    "            enc_size = (\n",
    "                int(et_query(et_root, enc + [\"x\"])),\n",
    "                int(et_query(et_root, enc + [\"y\"])),\n",
    "                int(et_query(et_root, enc + [\"z\"])),\n",
    "            )\n",
    "            rec = [\"encoding\", \"reconSpace\", \"matrixSize\"]\n",
    "            recon_size = (\n",
    "                int(et_query(et_root, rec + [\"x\"])),\n",
    "                int(et_query(et_root, rec + [\"y\"])),\n",
    "                int(et_query(et_root, rec + [\"z\"])),\n",
    "            )\n",
    "\n",
    "            lims = [\"encoding\", \"encodingLimits\", \"kspace_encoding_step_1\"]\n",
    "            enc_limits_center = int(et_query(et_root, lims + [\"center\"]))\n",
    "            enc_limits_max = int(et_query(et_root, lims + [\"maximum\"])) + 1\n",
    "\n",
    "            padding_left = enc_size[1] // 2 - enc_limits_center\n",
    "            padding_right = padding_left + enc_limits_max\n",
    "\n",
    "            num_slices = hf[\"kspace\"].shape[0]\n",
    "            \n",
    "            pathologies = self.pathology_df[self.pathology_df[\"file\"] == fname.name[:-3]]\n",
    "            \n",
    "            metadata = {\n",
    "                \"padding_left\": padding_left,\n",
    "                \"padding_right\": padding_right,\n",
    "                \"encoding_size\": enc_size,\n",
    "                \"recon_size\": recon_size,\n",
    "                \"pathologies\": pathologies,\n",
    "                **hf.attrs,\n",
    "            }\n",
    "            \n",
    "        return metadata, num_slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_samples)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        fname, dataslice, metadata, slice_pathologies = self.raw_samples[i]\n",
    "\n",
    "        with h5py.File(fname, \"r\") as hf:\n",
    "            kspace = hf[\"kspace\"][dataslice]\n",
    "\n",
    "            mask = np.asarray(hf[\"mask\"]) if \"mask\" in hf else None\n",
    "\n",
    "            image = hf[self.recons_key][dataslice] if self.recons_key in hf else None\n",
    "\n",
    "            attrs = dict(hf.attrs)\n",
    "            attrs.update(metadata)\n",
    "\n",
    "        if self.transform is None:\n",
    "            sample = (kspace, image, None, None, attrs, fname.name, dataslice, slice_pathologies)\n",
    "        else:\n",
    "            sample = self.transform(kspace, image, attrs, fname.name, dataslice, slice_pathologies)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for populating slices with pathology info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_slice_filter(clean_volumes, all_pathologies, raw_sample):\n",
    "    # Filter for populating slices with pathology information.\n",
    "    # (pathology info for volume also in metadata)\n",
    "    fname = raw_sample.fname\n",
    "    slice_ind = raw_sample.slice_ind\n",
    "    metadata = raw_sample.metadata\n",
    "    \n",
    "    pathologies_of_volume = metadata[\"pathologies\"]\n",
    "    # Pathologies in this slice\n",
    "    pathologies_of_slice = pathologies_of_volume[(pathologies_of_volume[\"slice\"] == slice_ind)]\n",
    "    # Replace empty list with n-hot of pathologies (needs to be n-hot for batching later)\n",
    "    one_hot_pathologies = np.zeros(len(all_pathologies), dtype=int)\n",
    "    for pathology in list(pathologies_of_slice[\"label\"].values):\n",
    "        one_hot_pathologies[all_pathologies.index(pathology)] += 1\n",
    "    \n",
    "    if one_hot_pathologies.sum() != len(list(pathologies_of_slice[\"label\"].values)):\n",
    "        raise RuntimeError(\"Pathologies got lost...\")\n",
    "        \n",
    "\n",
    "    raw_sample = raw_sample._replace(\n",
    "        slice_pathologies=one_hot_pathologies\n",
    "    )\n",
    "    \n",
    "    # Keep slices belonging to clean volumes AND slices with pathologies, \n",
    "    # BUT NOT slices in non-clean volumes that don't have pathologies.\n",
    "    # This is fine in terms of data numbers, because we have many more pathology volumes than clean volumes.\n",
    "    keep = clean_volumes[fname.name[:-3]] or len(pathologies_of_slice) > 0\n",
    "#     print(clean_volumes[fname.name[:-3]], len(pathologies_of_slice))\n",
    "    return raw_sample, keep\n",
    "    \n",
    "slice_filter = partial(partial(populate_slice_filter, clean_volumes), all_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_abs(data: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the absolute value of a complex valued input tensor.\n",
    "    Args:\n",
    "        data: A complex valued tensor, where the size of the final dimension\n",
    "            should be 2.\n",
    "    Returns:\n",
    "        Absolute value of data.\n",
    "    \"\"\"\n",
    "    if not data.shape[-1] == 2:\n",
    "        raise ValueError(\"Tensor does not have separate complex dim.\")\n",
    "\n",
    "    return (data**2).sum(dim=-1).sqrt()\n",
    "\n",
    "def fft2c(data: torch.Tensor, norm: str = \"ortho\") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply centered 2 dimensional Fast Fourier Transform.\n",
    "    Args:\n",
    "        data: Complex valued input data containing at least 3 dimensions:\n",
    "            dimensions -3 & -2 are spatial dimensions and dimension -1 has size\n",
    "            2. All other dimensions are assumed to be batch dimensions.\n",
    "        norm: Normalization mode. See ``torch.fft.fft``.\n",
    "    Returns:\n",
    "        The FFT of the input.\n",
    "    \"\"\"\n",
    "    if not data.shape[-1] == 2:\n",
    "        raise ValueError(\"Tensor does not have separate complex dim.\")\n",
    "\n",
    "    data = ifftshift(data, dim=[-3, -2])\n",
    "    data = torch.view_as_real(\n",
    "        torch.fft.fftn(  # type: ignore\n",
    "            torch.view_as_complex(data), dim=(-2, -1), norm=norm\n",
    "        )\n",
    "    )\n",
    "    data = fftshift(data, dim=[-3, -2])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def ifft2c(data: torch.Tensor, norm: str = \"ortho\") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply centered 2-dimensional Inverse Fast Fourier Transform.\n",
    "    Args:\n",
    "        data: Complex valued input data containing at least 3 dimensions:\n",
    "            dimensions -3 & -2 are spatial dimensions and dimension -1 has size\n",
    "            2. All other dimensions are assumed to be batch dimensions.\n",
    "        norm: Normalization mode. See ``torch.fft.ifft``.\n",
    "    Returns:\n",
    "        The IFFT of the input.\n",
    "    \"\"\"\n",
    "    if not data.shape[-1] == 2:\n",
    "        raise ValueError(\"Tensor does not have separate complex dim.\")\n",
    "\n",
    "    data = ifftshift(data, dim=[-3, -2])\n",
    "    data = torch.view_as_real(\n",
    "        torch.fft.ifftn(  # type: ignore\n",
    "            torch.view_as_complex(data), dim=(-2, -1), norm=norm\n",
    "        )\n",
    "    )\n",
    "    data = fftshift(data, dim=[-3, -2])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "\n",
    "def roll_one_dim(x: torch.Tensor, shift: int, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to roll but for only one dim.\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        shift: Amount to roll.\n",
    "        dim: Which dimension to roll.\n",
    "    Returns:\n",
    "        Rolled version of x.\n",
    "    \"\"\"\n",
    "    shift = shift % x.size(dim)\n",
    "    if shift == 0:\n",
    "        return x\n",
    "\n",
    "    left = x.narrow(dim, 0, x.size(dim) - shift)\n",
    "    right = x.narrow(dim, x.size(dim) - shift, shift)\n",
    "\n",
    "    return torch.cat((right, left), dim=dim)\n",
    "\n",
    "\n",
    "def roll(\n",
    "    x: torch.Tensor,\n",
    "    shift: List[int],\n",
    "    dim: List[int],\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.roll but applies to PyTorch Tensors.\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        shift: Amount to roll.\n",
    "        dim: Which dimension to roll.\n",
    "    Returns:\n",
    "        Rolled version of x.\n",
    "    \"\"\"\n",
    "    if len(shift) != len(dim):\n",
    "        raise ValueError(\"len(shift) must match len(dim)\")\n",
    "\n",
    "    for (s, d) in zip(shift, dim):\n",
    "        x = roll_one_dim(x, s, d)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def fftshift(x: torch.Tensor, dim: Optional[List[int]] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.fft.fftshift but applies to PyTorch Tensors\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        dim: Which dimension to fftshift.\n",
    "    Returns:\n",
    "        fftshifted version of x.\n",
    "    \"\"\"\n",
    "    if dim is None:\n",
    "        # this weird code is necessary for toch.jit.script typing\n",
    "        dim = [0] * (x.dim())\n",
    "        for i in range(1, x.dim()):\n",
    "            dim[i] = i\n",
    "\n",
    "    # also necessary for torch.jit.script\n",
    "    shift = [0] * len(dim)\n",
    "    for i, dim_num in enumerate(dim):\n",
    "        shift[i] = x.shape[dim_num] // 2\n",
    "\n",
    "    return roll(x, shift, dim)\n",
    "\n",
    "\n",
    "def ifftshift(x: torch.Tensor, dim: Optional[List[int]] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Similar to np.fft.ifftshift but applies to PyTorch Tensors\n",
    "    Args:\n",
    "        x: A PyTorch tensor.\n",
    "        dim: Which dimension to ifftshift.\n",
    "    Returns:\n",
    "        ifftshifted version of x.\n",
    "    \"\"\"\n",
    "    if dim is None:\n",
    "        # this weird code is necessary for toch.jit.script typing\n",
    "        dim = [0] * (x.dim())\n",
    "        for i in range(1, x.dim()):\n",
    "            dim[i] = i\n",
    "\n",
    "    # also necessary for torch.jit.script\n",
    "    shift = [0] * len(dim)\n",
    "    for i, dim_num in enumerate(dim):\n",
    "        shift[i] = (x.shape[dim_num] + 1) // 2\n",
    "\n",
    "    return roll(x, shift, dim)\n",
    "\n",
    "\n",
    "def to_tensor(data: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert numpy array to PyTorch tensor.\n",
    "    For complex arrays, the real and imaginary parts are stacked along the last\n",
    "    dimension.\n",
    "    Args:\n",
    "        data: Input numpy array.\n",
    "    Returns:\n",
    "        PyTorch version of data.\n",
    "    \"\"\"\n",
    "    if np.iscomplexobj(data):\n",
    "        data = np.stack((data.real, data.imag), axis=-1)\n",
    "\n",
    "    return torch.from_numpy(data)\n",
    "\n",
    "\n",
    "def center_crop(data: torch.Tensor, shape: Tuple[int, int]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply a center crop to the input real image or batch of real images.\n",
    "    Args:\n",
    "        data: The input tensor to be center cropped. It should\n",
    "            have at least 2 dimensions and the cropping is applied along the\n",
    "            last two dimensions.\n",
    "        shape: The output shape. The shape should be smaller\n",
    "            than the corresponding dimensions of data.\n",
    "    Returns:\n",
    "        The center cropped image.\n",
    "    \"\"\"\n",
    "    if not (0 < shape[0] <= data.shape[-2] and 0 < shape[1] <= data.shape[-1]):\n",
    "        raise ValueError(\"Invalid shapes.\")\n",
    "\n",
    "    w_from = (data.shape[-2] - shape[0]) // 2\n",
    "    h_from = (data.shape[-1] - shape[1]) // 2\n",
    "    w_to = w_from + shape[0]\n",
    "    h_to = h_from + shape[1]\n",
    "\n",
    "    return data[..., w_from:w_to, h_from:h_to]\n",
    "\n",
    "\n",
    "def complex_center_crop(data: torch.Tensor, shape: Tuple[int, int]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply a center crop to the input image or batch of complex images.\n",
    "    Args:\n",
    "        data: The complex input tensor to be center cropped. It should have at\n",
    "            least 3 dimensions and the cropping is applied along dimensions -3\n",
    "            and -2 and the last dimensions should have a size of 2.\n",
    "        shape: The output shape. The shape should be smaller than the\n",
    "            corresponding dimensions of data.\n",
    "    Returns:\n",
    "        The center cropped image\n",
    "    \"\"\"\n",
    "    if not (0 < shape[0] <= data.shape[-3] and 0 < shape[1] <= data.shape[-2]):\n",
    "        raise ValueError(\"Invalid shapes.\")\n",
    "\n",
    "    w_from = (data.shape[-3] - shape[0]) // 2\n",
    "    h_from = (data.shape[-2] - shape[1]) // 2\n",
    "    w_to = w_from + shape[0]\n",
    "    h_to = h_from + shape[1]\n",
    "\n",
    "    return data[..., w_from:w_to, h_from:h_to, :]\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    data: torch.Tensor,\n",
    "    mean: Union[float, torch.Tensor],\n",
    "    stddev: Union[float, torch.Tensor],\n",
    "    eps: Union[float, torch.Tensor] = 0.0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize the given tensor.\n",
    "    Applies the formula (data - mean) / (stddev + eps).\n",
    "    Args:\n",
    "        data: Input data to be normalized.\n",
    "        mean: Mean value.\n",
    "        stddev: Standard deviation.\n",
    "        eps: Added to stddev to prevent dividing by zero.\n",
    "    Returns:\n",
    "        Normalized tensor.\n",
    "    \"\"\"\n",
    "    return (data - mean) / (stddev + eps)\n",
    "\n",
    "\n",
    "def normalize_instance(\n",
    "    data: torch.Tensor, eps: Union[float, torch.Tensor] = 0.0\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Normalize the given tensor  with instance norm/\n",
    "    Applies the formula (data - mean) / (stddev + eps), where mean and stddev\n",
    "    are computed from the data itself.\n",
    "    Args:\n",
    "        data: Input data to be normalized\n",
    "        eps: Added to stddev to prevent dividing by zero.\n",
    "    Returns:\n",
    "        torch.Tensor: Normalized tensor\n",
    "    \"\"\"\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "\n",
    "    return normalize(data, mean, std, eps), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathologyTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for pathology model with U-Net encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        crop_size: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            crop_size: int, size to crop to (square).\n",
    "        \"\"\"\n",
    "\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        kspace: np.ndarray,\n",
    "        target: np.ndarray,\n",
    "        attrs: Dict,\n",
    "        fname: str,\n",
    "        slice_ind: int,\n",
    "        pathology_labels: np.ndarray, \n",
    "    ) -> Tuple[ torch.Tensor, torch.Tensor, str, int, float]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kspace: Input k-space of shape (num_coils, rows, cols) for\n",
    "                multi-coil data or (rows, cols) for single coil data.\n",
    "            target: Target image.\n",
    "            attrs: Acquisition related information stored in the HDF5 object.\n",
    "            fname: File name.\n",
    "            slice_ind: Serial number of the slice.\n",
    "            pathology_labels: n-hot array of pathology labels.\n",
    "        Returns:\n",
    "            A tuple containing, zero-filled input image, the reconstruction\n",
    "            target, the mean used for normalization, the standard deviations\n",
    "            used for normalization, the filename, and the slice number.\n",
    "        \"\"\"\n",
    "        kspace = to_tensor(kspace)\n",
    "\n",
    "        # check for max value\n",
    "        max_value = attrs[\"max\"] if \"max\" in attrs.keys() else 0.0\n",
    "\n",
    "        # inverse Fourier transform to get zero filled solution\n",
    "        image = ifft2c(kspace)\n",
    "\n",
    "        # crop input to correct size\n",
    "        if target is not None:\n",
    "            true_crop_size = (target.shape[-2], target.shape[-1])\n",
    "        else:\n",
    "            true_crop_size = (attrs[\"recon_size\"][0], attrs[\"recon_size\"][1])\n",
    "\n",
    "        # check for FLAIR 203\n",
    "        if image.shape[-2] < true_crop_size[1]:\n",
    "            crop_size = (image.shape[-2], image.shape[-2])\n",
    "\n",
    "        # Crop image to stated resolution\n",
    "        image = complex_center_crop(image, true_crop_size)\n",
    "\n",
    "        # Proper image constructed from kspace. From here we can do cropping (also in kspace).\n",
    "        if self.crop_size is not None:\n",
    "            # to kspace\n",
    "            image = fft2c(image)\n",
    "            # crop in kspace\n",
    "            image = complex_center_crop(image, (self.crop_size, self.crop_size))\n",
    "            kspace = image\n",
    "            # to image space\n",
    "            image = ifft2c(image)        \n",
    "        \n",
    "        # absolute value\n",
    "        image = complex_abs(image)\n",
    "        \n",
    "#         # apply Root-Sum-of-Squares if multicoil data\n",
    "#         if self.which_challenge == \"multicoil\":\n",
    "#             image = fastmri.rss(image)\n",
    "\n",
    "        # normalize input\n",
    "        image, mean, std = normalize_instance(image, eps=1e-11)\n",
    "        image = image.clamp(-6, 6)\n",
    "        \n",
    "        # Flip image (upside down): NOTE: this means kspace will not correspond to exactly image anymore.\n",
    "        image = torch.flip(image, dims=(0,))\n",
    "\n",
    "        # Image constructed from kspace\n",
    "        return kspace, image, mean, std, attrs, fname, slice_ind, pathology_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Knee data all volumes have been checked. So create dict from `no_pathologies` and `any_pathologies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 128\n",
    "pathology_transform = PathologyTransform(crop_size=crop_size)\n",
    "\n",
    "sample_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PathologiesSliceDataset(\n",
    "    root=test,\n",
    "    challenge=\"singlecoil\",  # Doesn't do anything right now, because pathologies labeled using RSS.\n",
    "    transform=pathology_transform,\n",
    "    raw_sample_filter=slice_filter,  # For populating slices with pathologies.\n",
    "    pathology_df=pathology_df,  # For volume metadata and for populating slices with pathologies.\n",
    "    clean_volumes=clean_volumes,  # For equalising clean VS. pathology volumes.\n",
    "    seed=0,\n",
    "    use_center_slices_only=True,\n",
    "    sample_rate=sample_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PathologiesSliceDataset(\n",
    "    root=train,\n",
    "    challenge=\"singlecoil\",  # Doesn't do anything right now, because pathologies labeled using RSS.\n",
    "    transform=pathology_transform,\n",
    "    raw_sample_filter=slice_filter,  # For populating slices with pathologies.\n",
    "    pathology_df=pathology_df,  # For volume metadata and for populating slices with pathologies.\n",
    "    clean_volumes=clean_volumes,  # For equalising clean VS. pathology volumes.\n",
    "    seed=0,\n",
    "    use_center_slices_only=True,\n",
    "    sample_rate=sample_rate,\n",
    ")\n",
    "\n",
    "len(train_dataset.raw_samples)\n",
    "\n",
    "val_dataset = PathologiesSliceDataset(\n",
    "    root=val,\n",
    "    challenge=\"singlecoil\",  # Doesn't do anything right now, because pathologies labeled using RSS.\n",
    "    transform=pathology_transform,\n",
    "    raw_sample_filter=slice_filter,  # For populating slices with pathologies.\n",
    "    pathology_df=pathology_df,  # For volume metadata and for populating slices with pathologies.\n",
    "    clean_volumes=clean_volumes,  # For equalising clean VS. pathology volumes.\n",
    "    seed=0,\n",
    "    use_center_slices_only=True,\n",
    "    sample_rate=sample_rate,\n",
    ")\n",
    "\n",
    "len(val_dataset.raw_samples)\n",
    "\n",
    "# Train:\n",
    "# Total 27849\n",
    "# Total halved 14682\n",
    "# Total halved filtered 7879\n",
    "# Remaining (should match above) 7879\n",
    "# Clean vs. pathology counts {True: 2218, False: 5661}\n",
    "# Final remaining 4436\n",
    "\n",
    "# Val:\n",
    "# Total 7135\n",
    "# Total halved 3763\n",
    "# Total halved filtered 2119\n",
    "# Remaining (should match above) 2119\n",
    "# Clean vs. pathology counts {True: 816, False: 1303}\n",
    "# Final remaining 1632\n",
    "\n",
    "# Test:\n",
    "# Total 6893\n",
    "# Total halved 3633\n",
    "# Total halved filtered 1931\n",
    "# Remaining (should match above) 1931\n",
    "# Clean vs. pathology counts {True: 584, False: 1347}\n",
    "# Final remaining 1168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This should be:\n",
    "# # Equal clean and pathology counts.\n",
    "# # Only from slices in center half of volume.\n",
    "# # Pathology slices all actually have a pathology in them.\n",
    "\n",
    "# counts = {\"clean\": 0, \"pathology\": 0}\n",
    "# for sample in filtered_slices:\n",
    "#     target, attrs, fname, dataslice, slice_pathologies = sample\n",
    "#     if len(slice_pathologies) > 0:\n",
    "#         counts[\"pathology\"] += 1\n",
    "#     else:\n",
    "#         counts[\"clean\"] += 1\n",
    "        \n",
    "#     break\n",
    "        \n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 20\n",
    "sampler = None\n",
    "is_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=None,\n",
    "    sampler=sampler,\n",
    "    shuffle=is_train if sampler is None else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=None,\n",
    "    sampler=sampler,\n",
    "    shuffle=is_train if sampler is None else False,\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=None,\n",
    "    sampler=sampler,\n",
    "    shuffle=is_train if sampler is None else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Train classifier (use segmentation feature extractors?)\n",
    "- Split train+val+test as multiple experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "\n",
    "    O. Ronneberger, P. Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "    for biomedical image segmentation. In International Conference on Medical\n",
    "    image computing and computer-assisted intervention, pages 234–241.\n",
    "    Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans: int,\n",
    "        out_chans: int,\n",
    "        chans: int = 32,\n",
    "        num_pool_layers: int = 4,\n",
    "        drop_prob: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input to the U-Net model.\n",
    "            out_chans: Number of channels in the output to the U-Net model.\n",
    "            chans: Number of output channels of the first convolution layer.\n",
    "            num_pool_layers: Number of down-sampling and up-sampling layers.\n",
    "            drop_prob: Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for _ in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers.append(ConvBlock(ch, ch * 2, drop_prob))\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch * 2, drop_prob)\n",
    "\n",
    "        self.up_conv = nn.ModuleList()\n",
    "        self.up_transpose_conv = nn.ModuleList()\n",
    "        for _ in range(num_pool_layers - 1):\n",
    "            self.up_transpose_conv.append(TransposeConvBlock(ch * 2, ch))\n",
    "            self.up_conv.append(ConvBlock(ch * 2, ch, drop_prob))\n",
    "            ch //= 2\n",
    "\n",
    "        self.up_transpose_conv.append(TransposeConvBlock(ch * 2, ch))\n",
    "        self.up_conv.append(\n",
    "            nn.Sequential(\n",
    "                ConvBlock(ch * 2, ch, drop_prob),\n",
    "                nn.Conv2d(ch, self.out_chans, kernel_size=1, stride=1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def encoder(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "\n",
    "        Returns:\n",
    "            Output encoding tensor of shape `(N, encoding_dim)`.\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = image\n",
    "\n",
    "        # apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.avg_pool2d(output, kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        output = self.conv(output)\n",
    "        return output, stack\n",
    "    \n",
    "    def lin_decoder(self, encoding: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoding: Input encoding tensor of shape `(N, encoding_dim)`.\n",
    "\n",
    "        Returns:\n",
    "            Output class logit tensor of shape `(N, 2)`.\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H, W)`.\n",
    "        \"\"\"\n",
    "        output, stack = self.encoder(image)\n",
    "\n",
    "        # apply up-sampling layers\n",
    "        for transpose_conv, conv in zip(self.up_transpose_conv, self.up_conv):\n",
    "            downsample_layer = stack.pop()\n",
    "            output = transpose_conv(output)\n",
    "\n",
    "            # reflect pad on the right/botton if needed to handle odd input dimensions\n",
    "            padding = [0, 0, 0, 0]\n",
    "            if output.shape[-1] != downsample_layer.shape[-1]:\n",
    "                padding[1] = 1  # padding right\n",
    "            if output.shape[-2] != downsample_layer.shape[-2]:\n",
    "                padding[3] = 1  # padding bottom\n",
    "            if torch.sum(torch.tensor(padding)) != 0:\n",
    "                output = F.pad(output, padding, \"reflect\")\n",
    "\n",
    "            output = torch.cat([output, downsample_layer], dim=1)\n",
    "            output = conv(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, LeakyReLU activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans: int, out_chans: int, drop_prob: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input.\n",
    "            out_chans: Number of channels in the output.\n",
    "            drop_prob: Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H, W)`.\n",
    "        \"\"\"\n",
    "        return self.layers(image)\n",
    "\n",
    "\n",
    "class TransposeConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transpose Convolutional Block that consists of one convolution transpose\n",
    "    layers followed by instance normalization and LeakyReLU activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans: int, out_chans: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans: Number of channels in the input.\n",
    "            out_chans: Number of channels in the output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_chans, out_chans, kernel_size=2, stride=2, bias=False\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n",
    "\n",
    "        Returns:\n",
    "            Output tensor of shape `(N, out_chans, H*2, W*2)`.\n",
    "        \"\"\"\n",
    "        return self.layers(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, enc_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_size = enc_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        hidden_size = 512\n",
    "        self.linear = nn.Linear(enc_size, output_size)\n",
    "        self.linear1 = nn.Linear(enc_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, encoding):\n",
    "#         x = F.relu(self.linear1(encoding))\n",
    "#         x = self.linear2(x)\n",
    "#         return x\n",
    "        return self.linear(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans,\n",
    "        chans,\n",
    "        num_pool_layers,\n",
    "        drop_prob,\n",
    "        input_shape,\n",
    "        lr,\n",
    "        total_lr_gamma,\n",
    "        num_epochs,\n",
    "    ):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = PathologyClassifier(\n",
    "            in_chans, chans, num_pool_layers, drop_prob, input_shape\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Architecture params\n",
    "        self.in_chans = in_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # Optimiser params\n",
    "        self.lr = lr\n",
    "        self.total_lr_gamma = total_lr_gamma\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.optimiser = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        self.lr_gamma = total_lr_gamma ** (1 / num_epochs)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            self.optimiser, self.lr_gamma\n",
    "        )\n",
    "\n",
    "    def train_epoch(self, loader):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        self.model.train()\n",
    "        self.bce_loss.train()\n",
    "\n",
    "        extra_output = {}\n",
    "        epoch_loss = 0\n",
    "        total_samples = 0\n",
    "        for i, sample in enumerate(loader):\n",
    "            (\n",
    "                kspace,\n",
    "                image,\n",
    "                mean,\n",
    "                std,\n",
    "                attrs,\n",
    "                fname,\n",
    "                dataslice,\n",
    "                slice_pathologies,\n",
    "            ) = sample\n",
    "            total_samples += image.shape[0]\n",
    "\n",
    "            self.optimiser.zero_grad()\n",
    "\n",
    "            image = image.unsqueeze(1).to(self.device)\n",
    "            target = (\n",
    "                (slice_pathologies.sum(dim=1) > 0).unsqueeze(1).float().to(self.device)\n",
    "            )\n",
    "\n",
    "            logits = self.model(image)\n",
    "            loss = self.bce_loss(logits, target)\n",
    "            reduced_loss = loss.mean(dim=1).sum(dim=0)  # Sum over batch dim\n",
    "\n",
    "            epoch_loss += reduced_loss.item()\n",
    "\n",
    "            reduced_loss.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "        self.scheduler.step()\n",
    "\n",
    "        epoch_loss /= total_samples\n",
    "        extra_output[\"train_epoch_time\"] = time.perf_counter() - start_time\n",
    "        return epoch_loss, extra_output\n",
    "\n",
    "    def val_epoch(self, loader):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        self.model.eval()\n",
    "        self.bce_loss.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            extra_output = {}\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            total_samples = 0\n",
    "            for i, sample in enumerate(loader):\n",
    "                (\n",
    "                    kspace,\n",
    "                    image,\n",
    "                    mean,\n",
    "                    std,\n",
    "                    attrs,\n",
    "                    fname,\n",
    "                    dataslice,\n",
    "                    slice_pathologies,\n",
    "                ) = sample\n",
    "                total_samples += image.shape[0]\n",
    "\n",
    "                # Debugging: visualise images\n",
    "                #                 plt.imshow(image.cpu().numpy()[0])\n",
    "                #                 plt.show()\n",
    "                #                 break\n",
    "\n",
    "                image = image.unsqueeze(1).to(self.device)\n",
    "                target = (\n",
    "                    (slice_pathologies.sum(dim=1) > 0)\n",
    "                    .unsqueeze(1)\n",
    "                    .float()\n",
    "                    .to(self.device)\n",
    "                )\n",
    "                #                 target = torch.stack((target, 1-target), dim=1).to(self.device)\n",
    "\n",
    "                logits = self.model(image)\n",
    "\n",
    "                # Accuracy\n",
    "                labels = torch.sigmoid(logits) > 0.5\n",
    "                epoch_acc += (labels == target.byte()).sum().float().item()\n",
    "                # Loss\n",
    "                loss = self.bce_loss(logits, target)\n",
    "                reduced_loss = loss.mean(dim=1).sum(dim=0)  # Sum over batch dim\n",
    "\n",
    "                epoch_loss += reduced_loss.item()\n",
    "\n",
    "            epoch_loss /= total_samples\n",
    "            epoch_acc /= total_samples\n",
    "\n",
    "        extra_output[\"val_epoch_time\"] = time.perf_counter() - start_time\n",
    "        return epoch_loss, epoch_acc, extra_output\n",
    "\n",
    "    def train(self, train_loader, val_loader=None, print_every=10, eval_every=10):\n",
    "        start_time = time.perf_counter()\n",
    "        extra_output = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = {}  # Not computed every epoch, so dict to keep track of epochs.\n",
    "        val_accs = {}\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if epoch % print_every == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.num_epochs}\")\n",
    "            if val_loader is not None and epoch % eval_every == 0:\n",
    "                val_loss, val_acc, val_extra_output = self.val_epoch(val_loader)\n",
    "                val_losses[epoch] = val_loss\n",
    "                val_accs[epoch] = val_acc\n",
    "                extra_output[epoch][\"val\"] = val_extra_output\n",
    "                print(\n",
    "                    f\"   Val loss: {val_loss:.3f}, Val acc: {val_acc:.2f}, time: {val_extra_output['val_epoch_time']:.2f}s\"\n",
    "                )\n",
    "\n",
    "            train_loss, train_extra_output = self.train_epoch(train_loader)\n",
    "            print(\n",
    "                f\" Train loss: {train_loss:.3f}, time: {train_extra_output['train_epoch_time']:.2f}s\"\n",
    "            )\n",
    "            train_losses.append(np.mean(train_loss))\n",
    "            extra_output[epoch][\"train\"] = train_extra_output\n",
    "\n",
    "        val_loss, val_acc, val_extra_output = self.val_epoch(val_loader)\n",
    "        val_losses[epoch] = val_loss\n",
    "        val_accs[epoch] = val_acc\n",
    "        extra_output[epoch][\"val\"] = val_extra_output\n",
    "        print(\n",
    "            f\"   Val loss: {val_loss:.3f}, Val acc: {val_acc:.2f}, time: {val_extra_output['val_epoch_time']:.2f}s\"\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            train_losses,\n",
    "            val_losses,\n",
    "            val_accs,\n",
    "            extra_output,\n",
    "            time.perf_counter() - start_time,\n",
    "        )\n",
    "\n",
    "    def test(self, loader):\n",
    "        start_time = time.perf_counter()\n",
    "        extra_output = {}\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "\n",
    "        self.model.eval()\n",
    "        self.bce_loss.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            total_samples = 0\n",
    "            for i, sample in enumerate(loader):\n",
    "                (\n",
    "                    kspace,\n",
    "                    image,\n",
    "                    mean,\n",
    "                    std,\n",
    "                    attrs,\n",
    "                    fname,\n",
    "                    dataslice,\n",
    "                    slice_pathologies,\n",
    "                ) = sample\n",
    "                total_samples += image.shape[0]\n",
    "                # Preprocessing\n",
    "                image = image.unsqueeze(1).to(self.device)\n",
    "                target = (slice_pathologies.sum(dim=1) > 0).unsqueeze(1).float()\n",
    "                all_targets.append(target)\n",
    "                target = target.to(self.device)\n",
    "                # target = torch.stack((pathology_yes_no, 1-pathology_yes_no), dim=1).to(self.device)\n",
    "\n",
    "                # Run model\n",
    "                logits = self.model(image)\n",
    "                all_logits.append(logits.cpu())\n",
    "\n",
    "                # Accuracy\n",
    "                labels = torch.sigmoid(logits) > 0.5\n",
    "                test_acc += (labels == target.byte()).sum().float().item()\n",
    "\n",
    "                # Loss\n",
    "                loss = self.bce_loss(logits, target)\n",
    "                reduced_loss = loss.mean(dim=1).sum(dim=0)  # Sum over batch dim\n",
    "                test_loss += reduced_loss.item()\n",
    "\n",
    "            test_loss /= total_samples\n",
    "            test_acc /= total_samples\n",
    "\n",
    "        test_time = time.perf_counter() - start_time\n",
    "        extra_output[\"test_time\"] = test_time\n",
    "        extra_output[\"logits\"] = torch.cat(all_logits, axis=0)\n",
    "        extra_output[\"targets\"] = torch.cat(all_targets, axis=0)\n",
    "        print(\n",
    "            f\"Test loss: {test_loss:.3f}, Test acc: {test_acc:.2f} time: {test_time:.2f}s\"\n",
    "        )\n",
    "        return test_loss, test_acc, extra_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (crop_size, crop_size)\n",
    "in_chans = 1\n",
    "chans = 16\n",
    "num_pool_layers = 4\n",
    "drop_prob = 0.0\n",
    "\n",
    "num_epochs = 2\n",
    "lr = 1e-5\n",
    "total_lr_gamma = 1\n",
    "\n",
    "module = ModelModule(in_chans, chans, num_pool_layers, drop_prob, input_shape, lr, total_lr_gamma, num_epochs)\n",
    "print(\"Encoding size:\", module.model.enc_size)\n",
    "\n",
    "# Small testing \n",
    "# train_losses, val_losses, extra_output, total_time = module.train(\n",
    "#     test_loader, test_loader, num_epochs=10, print_every=1, eval_every=2\n",
    "# )\n",
    "              \n",
    "train_losses, val_losses, val_accs, extra_output, total_time = module.train(\n",
    "    train_loader, val_loader, print_every=1, eval_every=2\n",
    ")\n",
    "\n",
    "print(f\"Total time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_x = [key for key in sorted(val_losses.keys(), key=lambda x: int(x))]\n",
    "val_loss_y = [val_losses[key] for key in val_loss_x]\n",
    "val_acc_y = [val_accs[key] for key in val_loss_x]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, c=\"b\", label=\"train\")\n",
    "plt.plot(val_loss_x, val_loss_y, c=\"orange\", label=\"val\")\n",
    "plt.title(\"Learning curves\", fontsize=18)\n",
    "plt.ylabel(\"loss\", fontsize=15)\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_loss_x, val_acc_y, c=\"orange\", label=\"val\")\n",
    "plt.title(\"Accuracy\", fontsize=18)\n",
    "plt.ylabel(\"acc\", fontsize=15)\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss of ~0.51 = -ln(.6), means 60/40 classification \n",
    "\n",
    "# Best until now on 128x128: \n",
    "# train 0.234, val 0.517; ep10, b64, lr1e-5, c16, p4, d0.0\n",
    "# train 0.480, val 0.543; ep10, b64, lr1e-5, c16, p4, d0.1: still decreasing.\n",
    "# train 0.350, val 0.518; ep30, b64, lr1e-5, c16, p4, d0.1\n",
    "\n",
    "# Scheduler? Start a bit faster maybe? Decrease below 1e-5 around epoch 20 probably. 0-10: 1e4, 10-20: 1e5, 20-30: 1e6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_extra_output = module.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, c=\"b\", label=\"train\")\n",
    "plt.plot(val_loss_x, val_loss_y, c=\"orange\", label=\"val\")\n",
    "plt.title(\"Learning curves\", fontsize=18)\n",
    "plt.ylabel(\"loss\", fontsize=15)\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_loss_x, val_acc_y, c=\"orange\", label=\"val\")\n",
    "plt.axhline(test_acc, xmin=0.01, xmax=.99, c=\"green\", ls='--', label=\"test (last epoch)\")\n",
    "plt.title(\"Accuracy\", fontsize=18)\n",
    "plt.ylabel(\"acc\", fontsize=15)\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c2st_e_prob1(y, prob1, num_batches=None):\n",
    "    # H0\n",
    "    # p(y|x) of MLE under H0: p(y|x) = p(y), is just the empirical frequency of y in the test data.\n",
    "    emp_freq_class0 = 1 - (y[y == 1]).sum() / y.shape[0]\n",
    "    emp_freq_class1 = (y[y == 1]).sum() / y.shape[0]\n",
    "\n",
    "    # prob1 is probability of class 1 given by model\n",
    "    pred_prob_class0 = 1 - prob1\n",
    "    pred_prob_class1 = prob1\n",
    "\n",
    "    if num_batches is None:\n",
    "        log_eval = torch.sum(\n",
    "            y * torch.log(pred_prob_class1 / emp_freq_class1)\n",
    "            + (1 - y) * torch.log(pred_prob_class0 / emp_freq_class0)\n",
    "        ).double()\n",
    "        e_val = torch.exp(log_eval)\n",
    "\n",
    "    else:\n",
    "        e_val = 0\n",
    "        ratios = y * torch.log(pred_prob_class1 / emp_freq_class1) + (\n",
    "            1 - y\n",
    "        ) * torch.log(pred_prob_class0 / emp_freq_class0)\n",
    "        ind = torch.randperm(ratios.shape[0])\n",
    "        ratios = ratios[ind]\n",
    "        ratio_batches = [ratios[i::num_batches] for i in range(num_batches)]\n",
    "        for i in range(num_batches):\n",
    "            e_val = e_val + torch.exp(torch.sum(ratio_batches[i]))\n",
    "        e_val = e_val / num_batches\n",
    "\n",
    "    # E-value\n",
    "    return e_val\n",
    "\n",
    "def c2st_prob1(y, prob1):\n",
    "    # H0: accuracy=0.5 vs H1: accuracy>0.5\n",
    "    y_hat = (prob1 > 0.5).long()\n",
    "    accuracy = torch.sum(y.long() == y_hat) / y.shape[0]\n",
    "    n_te = y.shape[0]\n",
    "    stat = 2 * np.sqrt(n_te) * (accuracy - 0.5)\n",
    "    pval = 1 - Normal(0, 1).cdf(stat)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets are 1-dimensional\n",
    "targets = test_extra_output[\"targets\"]\n",
    "# logits are 1-dimensional\n",
    "test_logit1 = test_extra_output[\"logits\"]\n",
    "# test_prob1 is probability of class 1 given by model\n",
    "test_prob1 = torch.sigmoid(test_logit1)\n",
    "\n",
    "e_val = c2st_e_prob1(targets, test_prob1).item()\n",
    "print(f\"1 / E-value: {1 / e_val:.4f} (actual: {1 / e_val})\")\n",
    "p_val_c2st = c2st_prob1(targets, test_prob1).item()\n",
    "print(f\"    p-value: {p_val_c2st:.4f} (actual: {p_val_c2st})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2st",
   "language": "python",
   "name": "c2st"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
